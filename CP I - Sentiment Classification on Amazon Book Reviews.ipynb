{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Procedure Outline:\n",
    "\n",
    "1. Collect each set of books and merge all the books together.\n",
    "2. Get rid of all the columns except \"Review Text\" and \"Review Score\".\n",
    "3. Clean up \"Review Text\" column (text only) without modifying order/number of rows.\n",
    "4. Check to see if there is a 1:1 relationship between len(\"Review Text\") and len(\"Review Score\").\n",
    "5. Call function to build maxtrix; will have in the end: X, y and vectorizer.\n",
    "6. Convert \"Review Score\" to multiple classes: \"Negative\", \"Neutral\" and \"Positive\" classes.\n",
    "7. Now with X and y, able to run these values through M.L. Classifiers: M.N. Naive Bayes, Decision Tree and Random Forest.\n",
    "8. Each model's performance metrics analyzed in order to determine best classifier amongst three options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The purpose of this notebook is to use Machine Learning (M.L.) in order to classify\n",
    "Amazon book reviews into three different sentiments: negative, neutral and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from six.moves import range\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From each book that is read in create a pandas data frame for each one\n",
    "\n",
    "def all_books(books):\n",
    "    result = []\n",
    "    \n",
    "    i = 0  \n",
    "    while i < len(books):\n",
    "        more_elements = pd.read_csv(books[i], sep='\\t', \n",
    "                  names = [\"Review Score\", \"Tail of Review URL\", \"Review Title\", \"Review Text\"])  \n",
    "        result.append(more_elements) \n",
    "        i += 1 \n",
    "        \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in all book reviews\n",
    "\n",
    "books = [\"Andy-Weir-The-Martian.csv\", \"Donna-Tartt-The-Goldfinch.csv\", \n",
    "         \"EL-James-Fifty-Shades-of-Grey.csv\", \"Fillian_Flynn-Gone_Girl.csv\", \n",
    "         \"John-Green-The-Fault-in-our-Stars.csv\", \"Laura-Hillenbrand-Unbroken.csv\", \n",
    "         \"Paula_Hawkins-The-Girl-On-The-Train.csv\", \"Suzanne-Collins-The-Hunger-Games.csv\"]\n",
    "\n",
    "all_reviews = []\n",
    "all_reviews = all_books(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining all data frames to work off of one big data frame\n",
    "\n",
    "#Concat function used here\n",
    "comb_DFs = pd.concat([all_reviews[0], all_reviews[1], all_reviews[2], all_reviews[3], all_reviews[4], all_reviews[5], all_reviews[6], all_reviews[7]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243269"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To verify that combining data frames worked: Checking that number of reviews in new big data frame matches sum of reviews from all books\n",
    "\n",
    "len(comb_DFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Score</th>\n",
       "      <th>Tail of Review URL</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/gp/customer-reviews/RKMO449VT48H3?ASIN=149159...</td>\n",
       "      <td>4.7573214851 Stars</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I'm a ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/gp/customer-reviews/R3RDNZNCOMRN0K?ASIN=14915...</td>\n",
       "      <td>Who needs nail clippers?</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;\"I'm str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/gp/customer-reviews/R1TC15NPCF9GMW?ASIN=14915...</td>\n",
       "      <td>Abandoned on Mars</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;A futuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/RT3R8XN5KZZGW?ASIN=149159...</td>\n",
       "      <td>Excellent Story</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;Follow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R32NNLGY7QGRVJ?ASIN=14915...</td>\n",
       "      <td>Inventive, humorous, tedious</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R14NNZV8RFYM5K?ASIN=14915...</td>\n",
       "      <td>Cool science and tech...but no life on Mars</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;The Mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/gp/customer-reviews/R7IJIAHW6TK62?ASIN=149159...</td>\n",
       "      <td>Hard Sci-Fi For The Win!</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/gp/customer-reviews/R62IPW4T33YZ4?ASIN=149159...</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;A fascin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R3GFO6M9HJB5KZ?ASIN=14915...</td>\n",
       "      <td>Science is great, writing is fair.</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;Sorry......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R1RZMRWYGW49DM?ASIN=14915...</td>\n",
       "      <td>Best physics class ever!</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I just f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review Score                                 Tail of Review URL                                 Review Title                                        Review Text\n",
       "0           4.0  /gp/customer-reviews/RKMO449VT48H3?ASIN=149159...                           4.7573214851 Stars  <span class=\"a-size-base review-text\">I'm a ha...\n",
       "1           3.0  /gp/customer-reviews/R3RDNZNCOMRN0K?ASIN=14915...                     Who needs nail clippers?  <span class=\"a-size-base review-text\">\"I'm str...\n",
       "2           4.0  /gp/customer-reviews/R1TC15NPCF9GMW?ASIN=14915...                            Abandoned on Mars  <span class=\"a-size-base review-text\">A futuri...\n",
       "3           5.0  /gp/customer-reviews/RT3R8XN5KZZGW?ASIN=149159...                              Excellent Story  <span class=\"a-size-base review-text\">Follow t...\n",
       "4           5.0  /gp/customer-reviews/R32NNLGY7QGRVJ?ASIN=14915...                 Inventive, humorous, tedious  <span class=\"a-size-base review-text\">This is ...\n",
       "5           5.0  /gp/customer-reviews/R14NNZV8RFYM5K?ASIN=14915...  Cool science and tech...but no life on Mars  <span class=\"a-size-base review-text\">The Mart...\n",
       "6           3.0  /gp/customer-reviews/R7IJIAHW6TK62?ASIN=149159...                     Hard Sci-Fi For The Win!  <span class=\"a-size-base review-text\">I can't ...\n",
       "7           3.0  /gp/customer-reviews/R62IPW4T33YZ4?ASIN=149159...                                    Wonderful  <span class=\"a-size-base review-text\">A fascin...\n",
       "8           5.0  /gp/customer-reviews/R3GFO6M9HJB5KZ?ASIN=14915...           Science is great, writing is fair.  <span class=\"a-size-base review-text\">Sorry......\n",
       "9           5.0  /gp/customer-reviews/R1RZMRWYGW49DM?ASIN=14915...                     Best physics class ever!  <span class=\"a-size-base review-text\">I just f..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Took a look at the first entries of the big data frame\n",
    "\n",
    "comb_DFs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243269"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separating out the reviews column from the big data frame.\n",
    "#Also verifying that it has the same amount of rows as in the big data frame\n",
    "\n",
    "reviews = comb_DFs['Review Text']\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243269"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Separating out the scores column from the big data frame.\n",
    "#Also verifying that it has the same amount of rows as in the big data frame\n",
    "\n",
    "scores = comb_DFs['Review Score']\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span class=\"a-size-base review-text\">If I could rate this book a zero I would... The book was to all over the place.. Ive herd many good things about this book aand the others...Woorst book I hae EVER reead  Dont read it!!!!!!!!</span>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a look at what a raw review looks like\n",
    "reviews[243268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cleaning up the reviews so that what is remaining is pure text\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def cleaned_reviews(reviews):\n",
    "    result2 = []\n",
    "    for r in reviews:\n",
    "        r = r.lstrip('<span class=\"a-size-base review-text\">')\n",
    "        r = r.rstrip('</span>')\n",
    "        \n",
    "        r.replace('<br/><br/>', ' ')\n",
    "        r.replace('<br/>', ' ')\n",
    "        r.replace('\\\\','') \n",
    "           \n",
    "        table = string.maketrans(\"\",\"\") \n",
    "        r = r.translate(table, string.punctuation)\n",
    "        result2.append(r)\n",
    "\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calling function to clean up all reviews\n",
    "\n",
    "r_all = []\n",
    "r_all = cleaned_reviews(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If I could rate this book a zero I would The book was to all over the place Ive herd many good things about this book aand the othersWoorst book I hae EVER reead  Dont read it'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking cleaned_reviews function \n",
    "#Verifying that text is clean. \n",
    "\n",
    "r_all[243268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorizing reviews and scores (along with changing scores into three different sentiment classes) \n",
    "\n",
    "#Thank you to Harvard CS109 course and my mentor, AJ, for help with this portion.\n",
    "\n",
    "def buildMatrixAndVector(r_all, scores, vectorizer=None):\n",
    "    \n",
    "    # initialize vectorizer if none is provided\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    \n",
    "    # create X using the vectorizer on the reviews\n",
    "    X = vectorizer.fit_transform(r_all)\n",
    "    \n",
    "    # check out the type and shape of X\n",
    "    print(\"... in buildMatrixAndVector: \")\n",
    "    print(\"... type of X as returned by vectorizer.fit_transform(reviews): \" + str(type(X)))\n",
    "    print(\"... shape of X as returned by vectorizer.fit_transform(reviews): \" + str(X.shape))\n",
    "    \n",
    "    # transform X to compressed Sparse Column format (CSC)\n",
    "    X = X.tocsc()\n",
    "    \n",
    "    # check out the type and shape of X after the transformation\n",
    "    print(\"... in buildMatrixAndVector: \")\n",
    "    print(\"... type of X as transformed by tocsc(): \" + str(type(X)))\n",
    "    print(\"... shape of X as as transformed by tocsc(): \" + str(X.shape))\n",
    "    \n",
    "    # now get y from labels\n",
    "    # in this case this is a multi-class problem, so we \n",
    "    # transform {1, 2} to 1; {3} to 2; and {4, 5} to 3\n",
    "    # for sentiment classification - 1 = negative, 2 = neutral, 3 = positive\n",
    "    y = scores.apply(lambda x: 1 if x in range(1,3) \n",
    "                          else 3 if x in range(4,6) \n",
    "                          else 2)\n",
    "    \n",
    "    # check out the type and shape of y\n",
    "    print(\"... in buildMatrixAndVector: \")\n",
    "    print(\"... type of y: \" + str(type(y)))\n",
    "    print(\"... length of y: \" + str(y.shape))\n",
    "    \n",
    "    # return what we have built, including the vectorizer object\n",
    "    return X, y, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... in buildMatrixAndVector: \n",
      "... type of X as returned by vectorizer.fit_transform(reviews): <class 'scipy.sparse.csr.csr_matrix'>\n",
      "... shape of X as returned by vectorizer.fit_transform(reviews): (243269, 153408)\n",
      "... in buildMatrixAndVector: \n",
      "... type of X as transformed by tocsc(): <class 'scipy.sparse.csc.csc_matrix'>\n",
      "... shape of X as as transformed by tocsc(): (243269, 153408)\n",
      "... in buildMatrixAndVector: \n",
      "... type of y: <class 'pandas.core.series.Series'>\n",
      "... length of y: (243269,)\n"
     ]
    }
   ],
   "source": [
    "#Calling function using all of the cleaned up reviews and its paired scores\n",
    "\n",
    "X, y, vectorizer = buildMatrixAndVector(r_all, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mindyng/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.75\n",
      "Accuracy on test data:     0.72\n",
      "\n",
      "Processing time for MultinomialNB: 0.14372 secs\n"
     ]
    }
   ],
   "source": [
    "#Using MultiNomial Naive Bayes Classifier to predict reviews' sentiments\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "\n",
    "start_time = time.clock() \n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "proc_time = time.clock() - start_time\n",
    "\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "print (\"\\nProcessing time for MultinomialNB: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training and Testing Accuracies are pretty close. \n",
    "#This means that this model did not overfit on its Training data.\n",
    "#Therefore, it was able to generalize well enough in order to predict \n",
    "#unseen test data's classes well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.26      0.33      9628\n",
      "          2       0.19      0.02      0.04      6879\n",
      "          3       0.76      0.93      0.84     44311\n",
      "\n",
      "avg / total       0.65      0.72      0.67     60818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for M.N. Naive Bayes Classifier\n",
    "\n",
    "# classification_report() function displays the \n",
    "# precision, recall, f1-score and support for each class.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "report = classification_report(ytest, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Precision:  ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is the accuracy of the positive predictions.\n",
    "# The best value is 1 and the worst value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall: ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "# The best value is 1 and the worst value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F-1 Score: weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "# F1 = 2 * (precision * recall) / (precision + recall)\n",
    "# In the multi-class and multi-label case, this is the weighted average of the F1 score of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on the classification report, prediction for category '2' was the worst,\n",
    "# category '1' was a little better. And prediction for category '3' was the best. \n",
    "\n",
    "# This makes sense since the training data is highly skewed towards\n",
    "# category 3. \n",
    "\n",
    "# Given the low Precision, Recall and F1-score values for categories\n",
    "# '1' and '2', there is room for improving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.76\n",
      "Accuracy on test data:     0.68\n",
      "Accuracy on training data: 0.75\n",
      "Accuracy on test data:     0.72\n",
      "Accuracy on training data: 0.74\n",
      "Accuracy on test data:     0.73\n",
      "Accuracy on training data: 0.73\n",
      "Accuracy on test data:     0.73\n",
      "Accuracy on training data: 0.73\n",
      "Accuracy on test data:     0.73\n",
      "\n",
      "Processing time for 5 runs of MultinomialNB: 4.875137 secs\n"
     ]
    }
   ],
   "source": [
    "#Trying to improve classifier performance by tuning MultiNomial Naive Bayes Classifier's alpha parameter \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "alphas = [.1, 1, 5, 10, 50]\n",
    "    \n",
    "start_time = time.clock()\n",
    "for i in alphas:\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "    clf = MultinomialNB(i).fit(xtrain, ytrain)\n",
    "\n",
    "    training_accuracy = clf.score(xtrain, ytrain)\n",
    "    test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "proc_time = time.clock() - start_time\n",
    "print (\"\\nProcessing time for 5 runs of MultinomialNB: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing different alpha values did improve performance by huge amount. \n",
    "# Durng this run, alpha = 0.1 had the highest values. Also, training and test data were\n",
    "# very close, which means that training data was very good at setting up\n",
    "# model to use on new test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Due to the first alpha value = 0.1 giving the highest accuracy percentages, \n",
    "# this value is used to evaluate classification model's performance with Confusion Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.76\n",
      "Accuracy on test data:     0.67\n"
     ]
    }
   ],
   "source": [
    "#Isolating Training and Test Accuracy results from hyperparameter, alpha, set at 0.1\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf = MultinomialNB(0.1).fit(xtrain, ytrain)\n",
    "\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3202   743  5673]\n",
      " [  942   844  5213]\n",
      " [ 4184  3173 36844]]\n"
     ]
    }
   ],
   "source": [
    "#Other Performance metric on Multiclass Classifier - MultiNomial Naive Bayes Classifier\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = MultinomialNB(0.1)\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "matrix = confusion_matrix(ytest, predicted)\n",
    "print(matrix)\n",
    "\n",
    "# Each column represents instances of PREDICTED class\n",
    "# Each row represents instances in ACTUAL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAITCAYAAACExC9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5e0JACAiGgCAiGgAACKiAQCIiAYAIPIfqY+KDEgciXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1250cc4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Image representation of confusion matrix.\n",
    "\n",
    "plt.matshow(matrix, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The majority of the predictions do not fall on the diagonal of the line\n",
    "# of the matrix (which are the correct predictions).\n",
    "\n",
    "# The only value that is huge is the bottom right, which corresponds to \n",
    "# positive ratings. This makes sense since this category had the highest\n",
    "# proportion of traning data.\n",
    "\n",
    "# Let's try another classification model in order to improve model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.63\n",
      "\n",
      "Processing time for DecisionTreeClassifier: 883.85925 secs\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.clock() \n",
    "tree_clf.fit(xtrain,ytrain)\n",
    "proc_time = time.clock() - start_time\n",
    "\n",
    "training_accuracy2 = tree_clf.score(xtrain, ytrain)\n",
    "test_accuracy2 = tree_clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy2)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy2)\n",
    "print (\"\\nProcessing time for DecisionTreeClassifier: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.22      0.24      9618\n",
      "          2       0.13      0.10      0.11      6999\n",
      "          3       0.75      0.80      0.77     44201\n",
      "\n",
      "avg / total       0.60      0.63      0.61     60818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for Decision Tree Classifier\n",
    "\n",
    "# classification_report() function displays the \n",
    "# precision, recall, f1-score and support for each class.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "report = classification_report(ytest, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2116   836  6666]\n",
      " [  960   720  5319]\n",
      " [ 5198  3900 35103]]\n"
     ]
    }
   ],
   "source": [
    "#Other Performance metric on Multiclass Classifier - Decision Tree Classifier\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "matrix = confusion_matrix(ytest, predicted)\n",
    "print(matrix)\n",
    "\n",
    "# Each column represents instances of PREDICTED class\n",
    "# Each row represents instances in ACTUAL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.72\n",
      "\n",
      "Processing time for RandomForestClassifier: 668.978142 secs\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model:\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "start_time = time.clock()\n",
    "forest_clf.fit(xtrain, ytrain)\n",
    "proc_time = time.clock() - start_time\n",
    "\n",
    "training_accuracy3 = forest_clf.score(xtrain, ytrain)\n",
    "test_accuracy3 = forest_clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy3)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy3)\n",
    "print (\"\\nProcessing time for RandomForestClassifier: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.39      0.10      0.16      9618\n",
      "          2       0.14      0.01      0.02      6999\n",
      "          3       0.74      0.96      0.83     44201\n",
      "\n",
      "avg / total       0.61      0.72      0.63     60818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for Random Forest Classifier\n",
    "\n",
    "# classification_report() function displays the \n",
    "# precision, recall, f1-score and support for each class.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "report = classification_report(ytest, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  971   106  8541]\n",
      " [  236    84  6679]\n",
      " [ 1240   405 42556]]\n"
     ]
    }
   ],
   "source": [
    "#Other Performance metrics on Multiclass Classifier - Random Forest Classifier\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "matrix = confusion_matrix(ytest, predicted)\n",
    "print(matrix)\n",
    "\n",
    "# Each column represents instances of PREDICTED class\n",
    "# Each row represents instances in ACTUAL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model Performance Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mindyng/44.embed\" height=\"200px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "data_matrix = [['Model Performance Measurement', 'M.N. Naive Bayes', 'Decision Tree', 'Random Forest'],\n",
    "               ['Precision (Average)', 0.65, 0.6, 0.61], \n",
    "               ['Recall (Average)', 0.72,  0.63, .72],\n",
    "               ['Training Accuracy', .76, .99, .97],\n",
    "               ['Test Accuracy', .67, .63, .72]]\n",
    "\n",
    "table = ff.create_table(data_matrix)\n",
    "py.iplot(table, filename='simple_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion\n",
    "\n",
    "Precision: This tells us how exact the classifier is. \n",
    "The higher the number, the less false positives there are.\n",
    "\n",
    "Recall: This tells us how complete/sensitive the classifier is. \n",
    "The higher the number, the less false negatives there are. \n",
    "\n",
    "Accuracy: Percentage of correct predictions.\n",
    "\n",
    "Given, the model performance measurements with results closest to 1.0 will be the best predicting model. \n",
    "And the winner is Random Forest model since it has overall high performance measurements across the board."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
