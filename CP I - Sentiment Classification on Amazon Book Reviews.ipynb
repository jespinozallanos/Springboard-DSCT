{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the outlined procedure:\n",
    "\n",
    "# 1. Collect each set of books and merge all the books together.\n",
    "# 2. Get rid of all the columns except \"Review Text\" and \"Review Score\".\n",
    "# 3. Clean up \"Review Text\" column (text only) without modifying order/number of rows.\n",
    "# 4. Check to see if there is a 1:1 relationship between len(\"Review Text\") and len(\"Review Score\").\n",
    "# 5. Call function to build maxtrix; will have in the end: X, y and vectorizer.\n",
    "# 6. Convert \"Review Score\" to multiple classes: \"Negative\", \"Neutral\" and \"Positive\" classes.\n",
    "# 7. Now with X and y, able to run these values through M.L. Classifiers: M.N. Naive Bayes, Decision Tree and Random Forest.\n",
    "# 8. M.N. Naive Bayes algorithm results have \n",
    "# 9. Each model's performance metrics analyzed in order to determine best classifier amongst three options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The purpose of this notebook is to use Machine Learning (M.L.) in order to classify\n",
    "#amazon book reviews into three different sentiments: negative, neutral and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from six.moves import range\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From each book that is read in create a pandas data frame for each one\n",
    "\n",
    "def all_books(books):\n",
    "    result = []\n",
    "    \n",
    "    i = 0  \n",
    "    while i < len(books):\n",
    "        more_elements = pd.read_csv(books[i], sep='\\t', \n",
    "                  names = [\"Review Score\", \"Tail of Review URL\", \"Review Title\", \"Review Text\"])  \n",
    "        result.append(more_elements) \n",
    "        i += 1 \n",
    "        \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in all book reviews\n",
    "\n",
    "books = [\"Andy-Weir-The-Martian.csv\", \"Donna-Tartt-The-Goldfinch.csv\", \n",
    "         \"EL-James-Fifty-Shades-of-Grey.csv\", \"Fillian_Flynn-Gone_Girl.csv\", \n",
    "         \"John-Green-The-Fault-in-our-Stars.csv\", \"Laura-Hillenbrand-Unbroken.csv\", \n",
    "         \"Paula_Hawkins-The-Girl-On-The-Train.csv\", \"Suzanne-Collins-The-Hunger-Games.csv\"]\n",
    "\n",
    "all_reviews = []\n",
    "all_reviews = all_books(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining all data frames to work off of one big data frame\n",
    "\n",
    "#Concat function used here\n",
    "comb_DFs = pd.concat([all_reviews[0], all_reviews[1], all_reviews[2], all_reviews[3], all_reviews[4], all_reviews[5], all_reviews[6], all_reviews[7]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To verify that combining data frames worked: Checking that number of reviews in new big data frame matches sum of reviews from all books\n",
    "\n",
    "len(comb_DFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Score</th>\n",
       "      <th>Tail of Review URL</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/gp/customer-reviews/RKMO449VT48H3?ASIN=149159...</td>\n",
       "      <td>4.7573214851 Stars</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I'm a ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/gp/customer-reviews/R3RDNZNCOMRN0K?ASIN=14915...</td>\n",
       "      <td>Who needs nail clippers?</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;\"I'm str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/gp/customer-reviews/R1TC15NPCF9GMW?ASIN=14915...</td>\n",
       "      <td>Abandoned on Mars</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;A futuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/RT3R8XN5KZZGW?ASIN=149159...</td>\n",
       "      <td>Excellent Story</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;Follow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R32NNLGY7QGRVJ?ASIN=14915...</td>\n",
       "      <td>Inventive, humorous, tedious</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R14NNZV8RFYM5K?ASIN=14915...</td>\n",
       "      <td>Cool science and tech...but no life on Mars</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;The Mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/gp/customer-reviews/R7IJIAHW6TK62?ASIN=149159...</td>\n",
       "      <td>Hard Sci-Fi For The Win!</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/gp/customer-reviews/R62IPW4T33YZ4?ASIN=149159...</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;A fascin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R3GFO6M9HJB5KZ?ASIN=14915...</td>\n",
       "      <td>Science is great, writing is fair.</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;Sorry......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/gp/customer-reviews/R1RZMRWYGW49DM?ASIN=14915...</td>\n",
       "      <td>Best physics class ever!</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I just f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review Score                                 Tail of Review URL                                 Review Title                                        Review Text\n",
       "0           4.0  /gp/customer-reviews/RKMO449VT48H3?ASIN=149159...                           4.7573214851 Stars  <span class=\"a-size-base review-text\">I'm a ha...\n",
       "1           3.0  /gp/customer-reviews/R3RDNZNCOMRN0K?ASIN=14915...                     Who needs nail clippers?  <span class=\"a-size-base review-text\">\"I'm str...\n",
       "2           4.0  /gp/customer-reviews/R1TC15NPCF9GMW?ASIN=14915...                            Abandoned on Mars  <span class=\"a-size-base review-text\">A futuri...\n",
       "3           5.0  /gp/customer-reviews/RT3R8XN5KZZGW?ASIN=149159...                              Excellent Story  <span class=\"a-size-base review-text\">Follow t...\n",
       "4           5.0  /gp/customer-reviews/R32NNLGY7QGRVJ?ASIN=14915...                 Inventive, humorous, tedious  <span class=\"a-size-base review-text\">This is ...\n",
       "5           5.0  /gp/customer-reviews/R14NNZV8RFYM5K?ASIN=14915...  Cool science and tech...but no life on Mars  <span class=\"a-size-base review-text\">The Mart...\n",
       "6           3.0  /gp/customer-reviews/R7IJIAHW6TK62?ASIN=149159...                     Hard Sci-Fi For The Win!  <span class=\"a-size-base review-text\">I can't ...\n",
       "7           3.0  /gp/customer-reviews/R62IPW4T33YZ4?ASIN=149159...                                    Wonderful  <span class=\"a-size-base review-text\">A fascin...\n",
       "8           5.0  /gp/customer-reviews/R3GFO6M9HJB5KZ?ASIN=14915...           Science is great, writing is fair.  <span class=\"a-size-base review-text\">Sorry......\n",
       "9           5.0  /gp/customer-reviews/R1RZMRWYGW49DM?ASIN=14915...                     Best physics class ever!  <span class=\"a-size-base review-text\">I just f..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Took a look at the first entries of the big data frame\n",
    "\n",
    "comb_DFs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243269"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separating out the reviews column from the big data frame.\n",
    "#Also verifying that it has the same amount of rows as in the big data frame\n",
    "\n",
    "reviews = comb_DFs['Review Text']\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243269"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Separating out the scores column from the big data frame.\n",
    "#Also verifying that it has the same amount of rows as in the big data frame\n",
    "\n",
    "scores = comb_DFs['Review Score']\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span class=\"a-size-base review-text\">If I could rate this book a zero I would... The book was to all over the place.. Ive herd many good things about this book aand the others...Woorst book I hae EVER reead  Dont read it!!!!!!!!</span>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a look at what a raw review looks like\n",
    "reviews[243268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cleaning up the reviews so that what is remaining is pure text\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def cleaned_reviews(reviews):\n",
    "    result2 = []\n",
    "    for r in reviews:\n",
    "        r = r.lstrip('<span class=\"a-size-base review-text\">')\n",
    "        r = r.rstrip('</span>')\n",
    "        \n",
    "        r.replace('<br/><br/>', ' ')\n",
    "        r.replace('<br/>', ' ')\n",
    "        r.replace('\\\\','') \n",
    "           \n",
    "        table = string.maketrans(\"\",\"\") \n",
    "        r = r.translate(table, string.punctuation)\n",
    "        result2.append(r)\n",
    "\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calling function to clean up all reviews\n",
    "\n",
    "r_all = []\n",
    "r_all = cleaned_reviews(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If I could rate this book a zero I would The book was to all over the place Ive herd many good things about this book aand the othersWoorst book I hae EVER reead  Dont read it'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking cleaned_reviews function \n",
    "#Verifying that text is clean. \n",
    "\n",
    "r_all[243268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorizing reviews and scores (along with changing scores into three different sentiment classes) \n",
    "\n",
    "#Thank you to Harvard CS109 course and my mentor, AJ, for help with this portion.\n",
    "\n",
    "def buildMatrixAndVector(r_all, scores, vectorizer=None):\n",
    "    \n",
    "    # initialize vectorizer if none is provided\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    \n",
    "    # create X using the vectorizer on the reviews\n",
    "    X = vectorizer.fit_transform(r_all)\n",
    "    \n",
    "    # check out the type and shape of X\n",
    "    print(\"... in buildMatrixAndVector: \")\n",
    "    print(\"... type of X as returned by vectorizer.fit_transform(reviews): \" + str(type(X)))\n",
    "    print(\"... shape of X as returned by vectorizer.fit_transform(reviews): \" + str(X.shape))\n",
    "    \n",
    "    # transform X to compressed Sparse Column format (CSC)\n",
    "    X = X.tocsc()\n",
    "    \n",
    "    # check out the type and shape of X after the transformation\n",
    "    print(\"... in buildMatrixAndVector: \")\n",
    "    print(\"... type of X as transformed by tocsc(): \" + str(type(X)))\n",
    "    print(\"... shape of X as as transformed by tocsc(): \" + str(X.shape))\n",
    "    \n",
    "    # now get y from labels\n",
    "    # in this case this is a multi-class problem, so we \n",
    "    # transform {1, 2} to 1; {3} to 2; and {4, 5} to 3\n",
    "    # for sentiment classification - 1 = negative, 2 = neutral, 3 = positive\n",
    "    y = scores.apply(lambda x: 1 if x in range(1,3) \n",
    "                          else 3 if x in range(4,6) \n",
    "                          else 2)\n",
    "    \n",
    "    # check out the type and shape of y\n",
    "    print(\"... in buildMatrixAndVector: \")\n",
    "    print(\"... type of y: \" + str(type(y)))\n",
    "    print(\"... length of y: \" + str(y.shape))\n",
    "    \n",
    "    # return what we have built, including the vectorizer object\n",
    "    return X, y, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... in buildMatrixAndVector: \n",
      "... type of X as returned by vectorizer.fit_transform(reviews): <class 'scipy.sparse.csr.csr_matrix'>\n",
      "... shape of X as returned by vectorizer.fit_transform(reviews): (243269, 153408)\n",
      "... in buildMatrixAndVector: \n",
      "... type of X as transformed by tocsc(): <class 'scipy.sparse.csc.csc_matrix'>\n",
      "... shape of X as as transformed by tocsc(): (243269, 153408)\n",
      "... in buildMatrixAndVector: \n",
      "... type of y: <class 'pandas.core.series.Series'>\n",
      "... length of y: (243269,)\n"
     ]
    }
   ],
   "source": [
    "#Calling function using all of the cleaned up reviews and its paired scores\n",
    "\n",
    "X, y, vectorizer = buildMatrixAndVector(r_all, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mindyng/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.75\n",
      "Accuracy on test data:     0.72\n",
      "\n",
      "Processing time for MultinomialNB: 0.152611 secs\n"
     ]
    }
   ],
   "source": [
    "#Using MultiNomial Naive Bayes Classifier to predict reviews' sentiments\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "\n",
    "start_time = time.clock() \n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "proc_time = time.clock() - start_time\n",
    "\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "print (\"\\nProcessing time for MultinomialNB: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training and Testing Accuracies are pretty close. \n",
    "#This means that this model did not overfit on its Training data.\n",
    "#Therefore, it was able to generalize well enough in order to predict \n",
    "#unseen test data's classes well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.27      0.34      9607\n",
      "          2       0.19      0.02      0.04      6886\n",
      "          3       0.76      0.93      0.84     44325\n",
      "\n",
      "avg / total       0.65      0.72      0.67     60818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for M.N. Naive Bayes Classifier\n",
    "\n",
    "# classification_report() function displays the \n",
    "# precision, recall, f1-score and support for each class.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "report = classification_report(ytest, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Precision:  ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is the accuracy of the positive predictions.\n",
    "# The best value is 1 and the worst value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall: ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "# The best value is 1 and the worst value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F-1 Score: weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "# F1 = 2 * (precision * recall) / (precision + recall)\n",
    "# In the multi-class and multi-label case, this is the weighted average of the F1 score of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on the classification report, category '2' did the worst,\n",
    "# category '1' did a little better. And the category that performed\n",
    "# the best was '3'. \n",
    "\n",
    "# This makes sense since the training data is highly skewed towards\n",
    "# category 3. \n",
    "\n",
    "# Given the low Precision, Recall and F1-score values for categories\n",
    "# '1' and '2', there is room for improving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.76\n",
      "Accuracy on test data:     0.68\n",
      "Accuracy on training data: 0.75\n",
      "Accuracy on test data:     0.72\n",
      "Accuracy on training data: 0.74\n",
      "Accuracy on test data:     0.73\n",
      "Accuracy on training data: 0.73\n",
      "Accuracy on test data:     0.73\n",
      "Accuracy on training data: 0.73\n",
      "Accuracy on test data:     0.73\n",
      "\n",
      "Processing time for 5 runs of MultinomialNB: 5.192195 secs\n"
     ]
    }
   ],
   "source": [
    "#Trying to improve classifier performance by tuning MultiNomial Naive Bayes Classifier's alpha parameter \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "alphas = [.1, 1, 5, 10, 50]\n",
    "    \n",
    "start_time = time.clock()\n",
    "for i in alphas:\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "    clf = MultinomialNB(i).fit(xtrain, ytrain)\n",
    "\n",
    "    training_accuracy = clf.score(xtrain, ytrain)\n",
    "    test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "proc_time = time.clock() - start_time\n",
    "print (\"\\nProcessing time for 5 runs of MultinomialNB: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing different alpha values did improve performance by huge amount. \n",
    "# Durng this run, alpha = 0.1 had the highest values. Also, training and test data were\n",
    "# very close, which means that training data was very good at setting up\n",
    "# model to use on new test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Due to the first alpha value = 0.1 giving the highest accuracy percentages, \n",
    "# this value is used to evaluate classification model's performance with Confusion Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.76\n",
      "Accuracy on test data:     0.67\n"
     ]
    }
   ],
   "source": [
    "#Isolating Training and Test Accuracy results from hyperparameter, alpha, set at 0.1\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf = MultinomialNB(0.1).fit(xtrain, ytrain)\n",
    "\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3160   717  5594]\n",
      " [  913   826  5237]\n",
      " [ 4304  3074 36993]]\n"
     ]
    }
   ],
   "source": [
    "#Other Performance metric on Multiclass Classifier - MultiNomial Naive Bayes Classifier\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = MultinomialNB(0.1)\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "matrix = confusion_matrix(ytest, predicted)\n",
    "print(matrix)\n",
    "\n",
    "# Each column represents instances of PREDICTED class\n",
    "# Each row represents instances in ACTUAL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAITCAYAAACExC9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nngAAIqIBAIiIBgAgIhoAgIhoAAAi/wFOrIoJMUVthQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120e55f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Image representation of confusion matrix.\n",
    "\n",
    "plt.matshow(matrix, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The majority of the predictions do not fall on the diagonal of the line\n",
    "# of the matrix (which are the correct predictions).\n",
    "\n",
    "# The only value that is huge is the bottom right, which corresponds to \n",
    "# positive ratings. This makes sense since this category had the highest\n",
    "# proportion of traning data.\n",
    "\n",
    "# Let's try another classification model in order to improve model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.63\n",
      "\n",
      "Processing time for DecisionTreeClassifier: 982.766481 secs\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.clock() \n",
    "tree_clf.fit(xtrain,ytrain)\n",
    "proc_time = time.clock() - start_time\n",
    "\n",
    "training_accuracy2 = tree_clf.score(xtrain, ytrain)\n",
    "test_accuracy2 = tree_clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy2)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy2)\n",
    "print (\"\\nProcessing time for DecisionTreeClassifier: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.23      0.24      9471\n",
      "          2       0.12      0.10      0.11      6976\n",
      "          3       0.75      0.80      0.77     44371\n",
      "\n",
      "avg / total       0.60      0.63      0.61     60818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for Decision Tree Classifier\n",
    "\n",
    "# classification_report() function displays the \n",
    "# precision, recall, f1-score and support for each class.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "report = classification_report(ytest, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2148   881  6442]\n",
      " [  977   710  5289]\n",
      " [ 5225  3863 35283]]\n"
     ]
    }
   ],
   "source": [
    "#Other Performance metric on Multiclass Classifier - Decision Tree Classifier\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "matrix = confusion_matrix(ytest, predicted)\n",
    "print(matrix)\n",
    "\n",
    "# Each column represents instances of PREDICTED class\n",
    "# Each row represents instances in ACTUAL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.72\n",
      "\n",
      "Processing time for RandomForestClassifier: 703.071913 secs\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model:\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "start_time = time.clock()\n",
    "forest_clf.fit(xtrain, ytrain)\n",
    "proc_time = time.clock() - start_time\n",
    "\n",
    "training_accuracy3 = forest_clf.score(xtrain, ytrain)\n",
    "test_accuracy3 = forest_clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy3)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy3)\n",
    "print (\"\\nProcessing time for RandomForestClassifier: \" + str(proc_time) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.10      0.16      9471\n",
      "          2       0.13      0.01      0.02      6976\n",
      "          3       0.74      0.96      0.84     44371\n",
      "\n",
      "avg / total       0.62      0.72      0.64     60818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for Random Forest Classifier\n",
    "\n",
    "# classification_report() function displays the \n",
    "# precision, recall, f1-score and support for each class.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "report = classification_report(ytest, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  955    90  8426]\n",
      " [  281    75  6620]\n",
      " [ 1212   390 42769]]\n"
     ]
    }
   ],
   "source": [
    "#Other Performance metrics on Multiclass Classifier - Random Forest Classifier\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "predicted = model.predict(xtest)\n",
    "matrix = confusion_matrix(ytest, predicted)\n",
    "print(matrix)\n",
    "\n",
    "# Each column represents instances of PREDICTED class\n",
    "# Each row represents instances in ACTUAL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model Performance Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mindyng/44.embed\" height=\"170px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "data_matrix = [['Data Set', 'M.N. Naive Bayes', 'Decision Tree', 'Random Forest'],\n",
    "               ['Training (Accuracy)', 0.76, 0.99, 0.97], \n",
    "               ['Test (Accuracy)', 0.67,  0.630, .72],\n",
    "               ['Processing Time (seconds)', .152611, 982.766481, 703.071913]]\n",
    "\n",
    "table = ff.create_table(data_matrix)\n",
    "py.iplot(table, filename='simple_table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Conclusion:\n",
    "\n",
    "#When using Accuracy as our model performance metric, we are looking for the highest numbers closest to 1.00.\n",
    "#Looking at values alone, Decision Tree model's Training Set has the highest score - 0.99.\n",
    "\n",
    "#However, when comparing Decision Tree model's Training set Accuracy to its Test set Accuracy, there is a huge gap between them - 0.36.\n",
    "#This means there was overfitting on its Training Set. So the model built on its Training set did not generalize well enough to predict on its Testing set well.\n",
    "\n",
    "#What is ideal would be closer Accuracy results between Training and Test sets. This is the case for the M.N. Naive Bayes Classifier model.\n",
    "#The gap between this model's Training and Test set was 0.09. This is a smaller gap than the one from the Decision Tree model.\n",
    "#However, these numbers are still not as high as ones that are seen in another competing model.\n",
    "\n",
    "#The Random Forest model has higher values at 0.97 for the Training set and 0.72 for the Test set. \n",
    "#And the gap between its Training Set and Test Set accuracies was 0.25. This is comparable to the Decision Tree\n",
    "#gap, but this model's gap is smaller. \n",
    "\n",
    "##Due to having high values for its Training Accuracy and its Test Accuracy and a relative small gap between its Training and Test sets, \n",
    "##Random Forest model wins for the best model for predicting sentiment classes on Amazon book reviews."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
